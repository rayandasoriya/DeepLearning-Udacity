{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3056, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2909, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our log-probabilities\n",
    "logps = model(images)\n",
    "# Calculate the loss with the logps and the labels\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images)\n",
    "loss = criterion(logps, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Before backward pass: \\n', None)\n",
      "('After backward pass: \\n', tensor([[ 0.0040,  0.0040,  0.0040,  ...,  0.0040,  0.0040,  0.0040],\n",
      "        [ 0.0006,  0.0006,  0.0006,  ...,  0.0006,  0.0006,  0.0006],\n",
      "        [-0.0044, -0.0044, -0.0044,  ..., -0.0044, -0.0044, -0.0044],\n",
      "        ...,\n",
      "        [-0.0010, -0.0010, -0.0010,  ..., -0.0010, -0.0010, -0.0010],\n",
      "        [ 0.0006,  0.0006,  0.0006,  ...,  0.0006,  0.0006,  0.0006],\n",
      "        [-0.0052, -0.0052, -0.0052,  ..., -0.0052, -0.0052, -0.0052]]))\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Initial weights - ', Parameter containing:\n",
      "tensor([[-0.0313, -0.0004, -0.0020,  ..., -0.0119, -0.0187, -0.0267],\n",
      "        [-0.0094, -0.0275,  0.0040,  ..., -0.0332,  0.0105,  0.0119],\n",
      "        [ 0.0223, -0.0301, -0.0064,  ..., -0.0225, -0.0094, -0.0216],\n",
      "        ...,\n",
      "        [-0.0343,  0.0285, -0.0330,  ...,  0.0112, -0.0113, -0.0139],\n",
      "        [ 0.0071, -0.0001,  0.0134,  ...,  0.0282,  0.0218,  0.0246],\n",
      "        [-0.0042, -0.0281, -0.0120,  ...,  0.0200,  0.0100, -0.0062]],\n",
      "       requires_grad=True))\n",
      "('Gradient -', tensor([[-0.0006, -0.0006, -0.0006,  ..., -0.0006, -0.0006, -0.0006],\n",
      "        [ 0.0011,  0.0011,  0.0011,  ...,  0.0011,  0.0011,  0.0011],\n",
      "        [-0.0036, -0.0036, -0.0036,  ..., -0.0036, -0.0036, -0.0036],\n",
      "        ...,\n",
      "        [-0.0007, -0.0007, -0.0007,  ..., -0.0007, -0.0007, -0.0007],\n",
      "        [ 0.0009,  0.0009,  0.0009,  ...,  0.0009,  0.0009,  0.0009],\n",
      "        [-0.0021, -0.0021, -0.0021,  ..., -0.0021, -0.0021, -0.0021]]))\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Updated weights - ', Parameter containing:\n",
      "tensor([[ 0.0276, -0.0351,  0.0014,  ...,  0.0220,  0.0309,  0.0143],\n",
      "        [-0.0027,  0.0266, -0.0186,  ...,  0.0214, -0.0348,  0.0161],\n",
      "        [ 0.0269, -0.0328, -0.0196,  ...,  0.0082, -0.0321, -0.0171],\n",
      "        ...,\n",
      "        [-0.0287, -0.0154, -0.0019,  ...,  0.0093, -0.0012, -0.0270],\n",
      "        [ 0.0080, -0.0353, -0.0052,  ...,  0.0018,  0.0298, -0.0242],\n",
      "        [ 0.0115,  0.0061,  0.0308,  ..., -0.0021,  0.0286, -0.0148]],\n",
      "       requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Take an update step and few the new weights\n",
    "optimizer.step()\n",
    "print('Updated weights - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training loss ', 1.7933303727142846)\n",
      "('Training loss ', 0.7599538720048058)\n",
      "('Training loss ', 0.49495745941138725)\n",
      "('Training loss ', 0.41672061869838856)\n",
      "('Training loss ', 0.3781554452074108)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Training loss \" ,running_loss/len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
